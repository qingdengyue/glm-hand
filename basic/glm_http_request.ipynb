{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import jwt\n",
    "import time\n",
    "\n",
    "def generate_token(apikey:str,exp_seconds:int):\n",
    "    try:\n",
    "        id,secret=apikey.split(\".\")\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Invalid apikey\",e)\n",
    "    \n",
    "    payload={\n",
    "         \"api_key\":id,\n",
    "         \"exp\":int(round(time.time()*1000))+exp_seconds*1000,\n",
    "        \"timestamp\":int(round(time.time()*1000))\n",
    "    }\n",
    "\n",
    "    return jwt.encode(\n",
    "        payload,\n",
    "        secret,\n",
    "        algorithm=\"HS256\",\n",
    "        headers={\"alg\":\"HS256\",\"sign_type\":\"SIGN\"}\n",
    "    )\n",
    "\n",
    "\n",
    "api_key=os.environ[\"ZHIPUAI_API_KEY\"]\n",
    "token=generate_token(api_key,60)\n",
    "url = \"https://open.bigmodel.cn/api/paas/v4/chat/completions\"\n",
    "headers={\n",
    "     \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {token}\"\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"glm-4\",\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"your are a helpful assistant\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"can you tell me a joke?\"\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 8192,\n",
    "    \"temperature\": 0.8,\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "response=requests.post(url,headers=headers,json=data)\n",
    "ans=response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'content': \"Here's a light-hearted joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\\n\\nI hope that brings a smile to your face! If you want to hear more jokes, feel free to ask.\",\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1710818674,\n",
       " 'id': '8489586804394253002',\n",
       " 'model': 'glm-4',\n",
       " 'request_id': '8489586804394253002',\n",
       " 'usage': {'completion_tokens': 47, 'prompt_tokens': 19, 'total_tokens': 66}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a light-hearted joke for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n",
      "I hope that brings a smile to your face! If you want to hear more jokes, feel free to ask.\n",
      "8489586804394253002\n"
     ]
    }
   ],
   "source": [
    "print(ans[\"choices\"][0][\"message\"][\"content\"])\n",
    "print(ans[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'glm-4', 'messages': [{'role': 'system', 'content': 'your are a helpful assistant'}, {'role': 'user', 'content': 'can you tell me a joke?'}], 'max_tokens': 8192, 'temperature': 0.8, 'stream': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'content': \"Sure, here's a light-hearted joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\",\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1710819280,\n",
       " 'id': '8489581822231979837',\n",
       " 'model': 'glm-4',\n",
       " 'request_id': '8489581822231979837',\n",
       " 'usage': {'completion_tokens': 26, 'prompt_tokens': 19, 'total_tokens': 45}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"stream\"]=False\n",
    "api_key=os.environ[\"ZHIPUAI_API_KEY\"]\n",
    "token=generate_token(api_key,60)\n",
    "url = \"https://open.bigmodel.cn/api/paas/v4/chat/completions\"\n",
    "headers={\n",
    "     \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {token}\"\n",
    "}\n",
    "print(data)\n",
    "response=requests.post(url,headers=headers,json=data)\n",
    "ans=response.json()\n",
    "ans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in response.iter_lines():\n",
    "    if chunk:\n",
    "        chunk_str=chunk.decode(\"utf-8\")\n",
    "        json_start_pos=chunk_str.find('{\"id\"}')\n",
    "        if json_start_pos!=-1:\n",
    "              json_str=chunk_str[json_start_pos:]\n",
    "              json_data=json.loads(json_str)\n",
    "              for choice in json_data.get(\"choices\",[]):\n",
    "                delta=choice.get('delta',{})\n",
    "                content=delta.get('content',{})\n",
    "                print(content,end='|')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
